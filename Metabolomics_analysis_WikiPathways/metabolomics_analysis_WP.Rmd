---
title: "metabolomics_analysis"
author: 
- "ddedesener"
- "DeniseSl22"
date: "25/04/2022"
output:
 md_document:
    variant: markdown_github
always_allow_html: true
---

## Introduction
In this workflow, we will apply statistical analysis on metabolomics data and link the metabolites of interest to pathway data from WikiPathways.

First we download the required data.
```{r data_download,warning=FALSE, message=FALSE}
# Set Working Directory, download data and store in /Data folder
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
work_DIR <- getwd()

# Obtain a file locally by its url
install.packages("downloader")
fileUrl <- "https://ibdmdb.org/tunnel/products/HMP2/Metabolites/1723/HMP2_metabolomics.csv.gz?accessType=DOWNLOAD"
require(downloader)
download(fileUrl, "data/metabolomics.csv.gz", mode = "wb")

#Note: if the URL download does not work, the zipped file is located on GitHub to continue the rest of this script.
if(!"R.utils" %in% installed.packages()){install.packages("R.utils")}
library(R.utils)
gunzip("data/metabolomics.csv.gz", remove=FALSE)

remove(fileUrl)
```

Second, we perform data extraction from the file, and process the data
```{r data_import,warning=FALSE, message=FALSE}
##DATA CLEANUP:

# Read in the csv file with data (note this might take some time, 81867 rows in original dataset)
mSet <- read.csv("data/metabolomics.csv", na.strings=c("", "NA"))

#Replace all empty values with NA
mSet[mSet==""] <- NA

#remove all lines with an empty value for the column called "HDMB"
mSet_Cleaned <- mSet[!is.na(mSet$"HMDB...Representative.ID."),]

#Remove all elements without an actual HMDB ID:
mSet_Cleaned_Ion <- mSet_Cleaned[!grepl("redundant ion", mSet_Cleaned$HMDB...Representative.ID.),]

if(!"dplyr" %in% installed.packages()){install.packages("dplyr")}
library(dplyr)

#IDs ending with a * (indicating ...) are placed in a separate column (to keep track of for future reference)
mSet_Cleaned_Star <- mSet_Cleaned_Ion%>%mutate(Star = case_when(
 grepl("[*]",mSet_Cleaned_Ion$HMDB...Representative.ID.) ~ 1
))

#Update IDs with a * to regular IDs.
mSet_Cleaned_HMDB <- data.frame(lapply(mSet_Cleaned_Star, function(x) {
                  gsub("[*]", "", x)
             }))

#Update IDs To new HMDB structure
mSet_Cleaned_HMDB_NEW <- data.frame(lapply(mSet_Cleaned_HMDB, function(x) {
                  gsub("HMDB", "HMDB00", x)
             }))


remove(mSet,mSet_Cleaned, mSet_Cleaned_Ion, mSet_Cleaned_Star, mSet_Cleaned_HMDB)

##DATA PROCESSING:

#Remove metabolites with < 50% data (located in columns 8-553.
removeLines <- rowSums(is.na(mSet_Cleaned_HMDB_NEW[,8-553]))
fifty_percent <- floor((553-8)/2)

mSet_MissingDataCounted <- cbind(mSet_Cleaned_HMDB_NEW, removeLines)
mSet_NoMissingData <- subset(mSet_MissingDataCounted, removeLines <= fifty_percent)

#Convert intensity data to numeric values                         
mSet_NoMissingData[ , c(8:553)] <- apply(mSet_NoMissingData[ , c(8:553)], 2, function(x) as.numeric(as.character(x)))

##TODO ask Duygu what this step does?
#set the rest features as column mean 

##normalization (see https://doi.org/10.1177%2F1469066720918446 and https://www.statology.org/transform-data-in-r/)
##Users can select different transformation styles here:
transformation <- "log_2" #log_2 transformation on intensity data selected for IBD dataset, other options: square_root, log_2, log_10

if(transformation == "cube_root"){
    mSet_transformed <- cbind(mSet_NoMissingData[,c(1:7,554,555)], mSet_NoMissingData[,8:553]^(1/3))
}else if(transformation == "square_root"){
    mSet_transformed <- cbind(mSet_NoMissingData[,c(1:7,554,555)], mSet_NoMissingData[,8:553]^(1/2))
}else if(transformation == "log_2"){
    mSet_transformed <- cbind(mSet_NoMissingData[,c(1:7,554,555)], log2(mSet_NoMissingData[,8:553]))
}else if(transformation == "log_10"){
    mSet_transformed <- cbind(mSet_NoMissingData[,c(1:7,554,555)], log10(mSet_NoMissingData[,8:553]))
}else{print("Warning: name for transformation not recognized")}

## Visualize the data after the transformation (for one sample to get an idea of suitability of transformation:
#create histogram for original distribution for first column with data
hist(mSet_NoMissingData$HSM5FZBQ, col='steelblue', main='Original')
#create histogram for log-transformed distribution 
hist(mSet_transformed$HSM5FZBQ, col='coral2', main=transformation)

## Testing if the transformation creates a normally distributed dataset (alpha >= 0.05)
##Calculate all Shapiro values for raw and transformed data:
mSet_NoMissingData_Shapiro <- lapply(mSet_NoMissingData[,8:553], shapiro.test)
mSet_transformed_Shapiro <- lapply(mSet_transformed[,10:555], shapiro.test)

#Obtain the p-values for raw and transformed data
mSet_NoMissingData_Shapiro_pvalues <- do.call(rbind, mSet_NoMissingData_Shapiro)
mSet_transformed_Shapiro_pvalues <- do.call(rbind, mSet_transformed_Shapiro)

## Count how often the p-value is above 0.05, to obtain an estimate of achieved normality due to transformation
mSet_NoMissingData_Shapiro_pvalues_sum <- sum(mSet_NoMissingData_Shapiro_pvalues[,2] >= 0.05, na.rm=TRUE)
mSet_transformed_Shapiro_pvalues_sum <- sum(mSet_transformed_Shapiro_pvalues[,2] >= 0.05, na.rm=TRUE)

eighty_percent <- floor(((553-8)/10)*8)

#Print relevant information:
if(mSet_transformed_Shapiro_pvalues_sum[1] > eighty_percent ){paste0("Data after ", transformation ," transformation seems to follow a normal distribution for more then 80% of your data")} else{
  print("Advised to select a different data transformation procedure")}

remove(mSet_Cleaned_HMDB_NEW, mSet_MissingDataCounted, mSet_NoMissingData, mSet_NoMissingData_Shapiro, mSet_NoMissingData_Shapiro_pvalues, mSet_transformed_Shapiro, mSet_transformed_Shapiro_pvalues, eighty_percent, fifty_percent, mSet_NoMissingData_Shapiro_pvalues_sum, mSet_transformed_Shapiro_pvalues_sum, transformation, removeLines)
```

## Calculate logFC and p-value
```{r basic_statistics, warning=FALSE, message=FALSE}
# The file called "sampleLabels" will be used to connect the column names to the correct disorder/control group.
##TODO: find location of this datasource, see issue  #7 on GitHub

##calculate logFC for 2 groups (CD vs control, UC vs control)  

##Calculate p-value for two groups based on two-tailed t-test.

##Check for duplicate IDs, only retain those which are significant.
```


## Volcano plot
--> Update script below, to create an Volcano plot without MetaboAnalystR

```{r volcano_plot,warning=FALSE, message=FALSE}
#See https://bioconductor.org/packages/devel/bioc/vignettes/EnhancedVolcano/inst/doc/EnhancedVolcano.html
if (!requireNamespace('BiocManager', quietly = TRUE))
    install.packages('BiocManager')
  BiocManager::install('EnhancedVolcano')

library(EnhancedVolcano)

```


Export the data:
```{r data_export, warning=FALSE, message=FALSE}
# Saving output
if(dir.exists("output"))#if the output folder already exist
  unlink("output", recursive=TRUE)#first delete the existing one
dir.create("output")#create a new output folder
```

